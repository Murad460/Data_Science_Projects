{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.15","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9762903,"sourceType":"datasetVersion","datasetId":5889785}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install nltk","metadata":{"execution":{"iopub.status.busy":"2024-10-31T06:08:17.068807Z","iopub.execute_input":"2024-10-31T06:08:17.069139Z","iopub.status.idle":"2024-10-31T06:08:21.950847Z","shell.execute_reply.started":"2024-10-31T06:08:17.069112Z","shell.execute_reply":"2024-10-31T06:08:21.949787Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"Collecting nltk\n  Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/site-packages (from nltk) (4.66.5)\nRequirement already satisfied: joblib in /usr/local/lib/python3.10/site-packages (from nltk) (1.4.2)\nRequirement already satisfied: click in /usr/local/lib/python3.10/site-packages (from nltk) (8.1.7)\nRequirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/site-packages (from nltk) (2024.9.11)\nInstalling collected packages: nltk\nSuccessfully installed nltk-3.9.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport nltk\nfrom nltk.corpus import stopwords\nimport re\nfrom nltk.tokenize import word_tokenize \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nnltk.download(\"punkt\")\nnltk.download(\"stopwords\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-31T06:08:21.952868Z","iopub.execute_input":"2024-10-31T06:08:21.953201Z","iopub.status.idle":"2024-10-31T06:08:23.295289Z","shell.execute_reply.started":"2024-10-31T06:08:21.953172Z","shell.execute_reply":"2024-10-31T06:08:23.294552Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package punkt to /root/nltk_data...\n[nltk_data]   Unzipping tokenizers/punkt.zip.\n[nltk_data] Downloading package stopwords to /root/nltk_data...\n[nltk_data]   Unzipping corpora/stopwords.zip.\n","output_type":"stream"},{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"df=pd.read_csv(\"/kaggle/input/full-netflix-dataset/data.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-10-31T06:08:23.296243Z","iopub.execute_input":"2024-10-31T06:08:23.297244Z","iopub.status.idle":"2024-10-31T06:08:23.407234Z","shell.execute_reply.started":"2024-10-31T06:08:23.297213Z","shell.execute_reply":"2024-10-31T06:08:23.406490Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2024-10-31T06:08:23.408884Z","iopub.execute_input":"2024-10-31T06:08:23.409147Z","iopub.status.idle":"2024-10-31T06:08:23.420319Z","shell.execute_reply.started":"2024-10-31T06:08:23.409119Z","shell.execute_reply":"2024-10-31T06:08:23.419623Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"url                   9158\ntitle                  500\ntype                     0\ngenres                 148\nreleaseYear             12\nimdbId                 682\nimdbAverageRating      726\nimdbNumVotes           726\navailableCountries       0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"df=df.drop(columns=[\"url\",\"imdbId\"])\n","metadata":{"execution":{"iopub.status.busy":"2024-10-31T06:08:23.421288Z","iopub.execute_input":"2024-10-31T06:08:23.421580Z","iopub.status.idle":"2024-10-31T06:08:23.433857Z","shell.execute_reply.started":"2024-10-31T06:08:23.421550Z","shell.execute_reply":"2024-10-31T06:08:23.433192Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2024-10-31T06:08:23.434734Z","iopub.execute_input":"2024-10-31T06:08:23.434998Z","iopub.status.idle":"2024-10-31T06:08:23.453192Z","shell.execute_reply.started":"2024-10-31T06:08:23.434972Z","shell.execute_reply":"2024-10-31T06:08:23.452461Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"                                      title   type                     genres  \\\n0                              Forrest Gump  movie             Drama, Romance   \n1                         The Fifth Element  movie  Action, Adventure, Sci-Fi   \n2                         Kill Bill: Vol. 1  movie    Action, Crime, Thriller   \n3                                   Jarhead  movie      Biography, Drama, War   \n4                                Unforgiven  movie             Drama, Western   \n...                                     ...    ...                        ...   \n15855                                   NaN     tv             Drama, Mystery   \n15856                                   NaN     tv                        NaN   \n15857                                   NaN     tv                        NaN   \n15858                                   NaN     tv                        NaN   \n15859  The Evolution of Black British Music     tv         Documentary, Music   \n\n       releaseYear  imdbAverageRating  imdbNumVotes  \\\n0           1994.0                8.8     2313221.0   \n1           1997.0                7.6      516523.0   \n2           2003.0                8.2     1220488.0   \n3           2005.0                7.0      211314.0   \n4           1992.0                8.2      443310.0   \n...            ...                ...           ...   \n15855          NaN                NaN           NaN   \n15856       2024.0                NaN           NaN   \n15857       2024.0                NaN           NaN   \n15858          NaN                NaN           NaN   \n15859       2022.0                7.2          16.0   \n\n                                      availableCountries  \n0                                                     MX  \n1                                             AT, CH, DE  \n2      AE, AL, AO, AT, AU, AZ, BG, BH, BY, CA, CI, CM...  \n3      AD, AE, AG, AL, AO, AR, AT, AZ, BA, BB, BE, BG...  \n4      AU, BA, BE, BG, CZ, HR, HU, MD, ME, MK, NZ, PL...  \n...                                                  ...  \n15855  AD, AE, AG, AL, AO, AR, AT, AU, AZ, BA, BB, BE...  \n15856                     HK, ID, IN, KR, MY, PH, SG, TH  \n15857  AL, AO, AU, AZ, BA, BB, BG, BM, BS, BY, BZ, CA...  \n15858  AG, AO, AR, AU, BB, BM, BO, BS, BZ, CA, CI, CL...  \n15859                             BM, GB, GG, GI, IE, TC  \n\n[15860 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>type</th>\n      <th>genres</th>\n      <th>releaseYear</th>\n      <th>imdbAverageRating</th>\n      <th>imdbNumVotes</th>\n      <th>availableCountries</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Forrest Gump</td>\n      <td>movie</td>\n      <td>Drama, Romance</td>\n      <td>1994.0</td>\n      <td>8.8</td>\n      <td>2313221.0</td>\n      <td>MX</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The Fifth Element</td>\n      <td>movie</td>\n      <td>Action, Adventure, Sci-Fi</td>\n      <td>1997.0</td>\n      <td>7.6</td>\n      <td>516523.0</td>\n      <td>AT, CH, DE</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Kill Bill: Vol. 1</td>\n      <td>movie</td>\n      <td>Action, Crime, Thriller</td>\n      <td>2003.0</td>\n      <td>8.2</td>\n      <td>1220488.0</td>\n      <td>AE, AL, AO, AT, AU, AZ, BG, BH, BY, CA, CI, CM...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Jarhead</td>\n      <td>movie</td>\n      <td>Biography, Drama, War</td>\n      <td>2005.0</td>\n      <td>7.0</td>\n      <td>211314.0</td>\n      <td>AD, AE, AG, AL, AO, AR, AT, AZ, BA, BB, BE, BG...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Unforgiven</td>\n      <td>movie</td>\n      <td>Drama, Western</td>\n      <td>1992.0</td>\n      <td>8.2</td>\n      <td>443310.0</td>\n      <td>AU, BA, BE, BG, CZ, HR, HU, MD, ME, MK, NZ, PL...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>15855</th>\n      <td>NaN</td>\n      <td>tv</td>\n      <td>Drama, Mystery</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>AD, AE, AG, AL, AO, AR, AT, AU, AZ, BA, BB, BE...</td>\n    </tr>\n    <tr>\n      <th>15856</th>\n      <td>NaN</td>\n      <td>tv</td>\n      <td>NaN</td>\n      <td>2024.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>HK, ID, IN, KR, MY, PH, SG, TH</td>\n    </tr>\n    <tr>\n      <th>15857</th>\n      <td>NaN</td>\n      <td>tv</td>\n      <td>NaN</td>\n      <td>2024.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>AL, AO, AU, AZ, BA, BB, BG, BM, BS, BY, BZ, CA...</td>\n    </tr>\n    <tr>\n      <th>15858</th>\n      <td>NaN</td>\n      <td>tv</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>AG, AO, AR, AU, BB, BM, BO, BS, BZ, CA, CI, CL...</td>\n    </tr>\n    <tr>\n      <th>15859</th>\n      <td>The Evolution of Black British Music</td>\n      <td>tv</td>\n      <td>Documentary, Music</td>\n      <td>2022.0</td>\n      <td>7.2</td>\n      <td>16.0</td>\n      <td>BM, GB, GG, GI, IE, TC</td>\n    </tr>\n  </tbody>\n</table>\n<p>15860 rows × 7 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df2=df.dropna(how=\"any\",axis=0)\ndf2.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2024-10-31T06:08:23.453941Z","iopub.execute_input":"2024-10-31T06:08:23.454187Z","iopub.status.idle":"2024-10-31T06:08:23.467098Z","shell.execute_reply.started":"2024-10-31T06:08:23.454163Z","shell.execute_reply":"2024-10-31T06:08:23.466454Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"title                 0\ntype                  0\ngenres                0\nreleaseYear           0\nimdbAverageRating     0\nimdbNumVotes          0\navailableCountries    0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"df2","metadata":{"execution":{"iopub.status.busy":"2024-10-31T06:08:23.467999Z","iopub.execute_input":"2024-10-31T06:08:23.468268Z","iopub.status.idle":"2024-10-31T06:08:23.481846Z","shell.execute_reply.started":"2024-10-31T06:08:23.468233Z","shell.execute_reply":"2024-10-31T06:08:23.481109Z"},"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"                                      title   type  \\\n0                              Forrest Gump  movie   \n1                         The Fifth Element  movie   \n2                         Kill Bill: Vol. 1  movie   \n3                                   Jarhead  movie   \n4                                Unforgiven  movie   \n...                                     ...    ...   \n15847                           Mr. McMahon     tv   \n15848                          Blood Legacy     tv   \n15849                 Chef's Table: Noodles     tv   \n15854                 Making It in Marbella     tv   \n15859  The Evolution of Black British Music     tv   \n\n                              genres  releaseYear  imdbAverageRating  \\\n0                     Drama, Romance       1994.0                8.8   \n1          Action, Adventure, Sci-Fi       1997.0                7.6   \n2            Action, Crime, Thriller       2003.0                8.2   \n3              Biography, Drama, War       2005.0                7.0   \n4                     Drama, Western       1992.0                8.2   \n...                              ...          ...                ...   \n15847  Biography, Crime, Documentary       2024.0                7.7   \n15848                Drama, Thriller       2024.0                7.4   \n15849                    Documentary       2024.0                7.5   \n15854                     Reality-TV       2024.0                4.5   \n15859             Documentary, Music       2022.0                7.2   \n\n       imdbNumVotes                                 availableCountries  \n0         2313221.0                                                 MX  \n1          516523.0                                         AT, CH, DE  \n2         1220488.0  AE, AL, AO, AT, AU, AZ, BG, BH, BY, CA, CI, CM...  \n3          211314.0  AD, AE, AG, AL, AO, AR, AT, AZ, BA, BB, BE, BG...  \n4          443310.0  AU, BA, BE, BG, CZ, HR, HU, MD, ME, MK, NZ, PL...  \n...             ...                                                ...  \n15847        6746.0  AD, AE, AG, AL, AO, AR, AT, AU, AZ, BA, BB, BE...  \n15848         101.0  AD, AE, AG, AL, AO, AR, AT, AU, AZ, BA, BB, BE...  \n15849         201.0  AD, AE, AL, AO, AR, AT, AU, AZ, BA, BB, BE, BG...  \n15854         139.0  AD, AE, AL, AO, AR, AT, AU, AZ, BA, BB, BE, BG...  \n15859          16.0                             BM, GB, GG, GI, IE, TC  \n\n[15134 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>type</th>\n      <th>genres</th>\n      <th>releaseYear</th>\n      <th>imdbAverageRating</th>\n      <th>imdbNumVotes</th>\n      <th>availableCountries</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Forrest Gump</td>\n      <td>movie</td>\n      <td>Drama, Romance</td>\n      <td>1994.0</td>\n      <td>8.8</td>\n      <td>2313221.0</td>\n      <td>MX</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The Fifth Element</td>\n      <td>movie</td>\n      <td>Action, Adventure, Sci-Fi</td>\n      <td>1997.0</td>\n      <td>7.6</td>\n      <td>516523.0</td>\n      <td>AT, CH, DE</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Kill Bill: Vol. 1</td>\n      <td>movie</td>\n      <td>Action, Crime, Thriller</td>\n      <td>2003.0</td>\n      <td>8.2</td>\n      <td>1220488.0</td>\n      <td>AE, AL, AO, AT, AU, AZ, BG, BH, BY, CA, CI, CM...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Jarhead</td>\n      <td>movie</td>\n      <td>Biography, Drama, War</td>\n      <td>2005.0</td>\n      <td>7.0</td>\n      <td>211314.0</td>\n      <td>AD, AE, AG, AL, AO, AR, AT, AZ, BA, BB, BE, BG...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Unforgiven</td>\n      <td>movie</td>\n      <td>Drama, Western</td>\n      <td>1992.0</td>\n      <td>8.2</td>\n      <td>443310.0</td>\n      <td>AU, BA, BE, BG, CZ, HR, HU, MD, ME, MK, NZ, PL...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>15847</th>\n      <td>Mr. McMahon</td>\n      <td>tv</td>\n      <td>Biography, Crime, Documentary</td>\n      <td>2024.0</td>\n      <td>7.7</td>\n      <td>6746.0</td>\n      <td>AD, AE, AG, AL, AO, AR, AT, AU, AZ, BA, BB, BE...</td>\n    </tr>\n    <tr>\n      <th>15848</th>\n      <td>Blood Legacy</td>\n      <td>tv</td>\n      <td>Drama, Thriller</td>\n      <td>2024.0</td>\n      <td>7.4</td>\n      <td>101.0</td>\n      <td>AD, AE, AG, AL, AO, AR, AT, AU, AZ, BA, BB, BE...</td>\n    </tr>\n    <tr>\n      <th>15849</th>\n      <td>Chef's Table: Noodles</td>\n      <td>tv</td>\n      <td>Documentary</td>\n      <td>2024.0</td>\n      <td>7.5</td>\n      <td>201.0</td>\n      <td>AD, AE, AL, AO, AR, AT, AU, AZ, BA, BB, BE, BG...</td>\n    </tr>\n    <tr>\n      <th>15854</th>\n      <td>Making It in Marbella</td>\n      <td>tv</td>\n      <td>Reality-TV</td>\n      <td>2024.0</td>\n      <td>4.5</td>\n      <td>139.0</td>\n      <td>AD, AE, AL, AO, AR, AT, AU, AZ, BA, BB, BE, BG...</td>\n    </tr>\n    <tr>\n      <th>15859</th>\n      <td>The Evolution of Black British Music</td>\n      <td>tv</td>\n      <td>Documentary, Music</td>\n      <td>2022.0</td>\n      <td>7.2</td>\n      <td>16.0</td>\n      <td>BM, GB, GG, GI, IE, TC</td>\n    </tr>\n  </tbody>\n</table>\n<p>15134 rows × 7 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data=df2[\"genres\"].str.split(',')\nfrom sklearn.preprocessing import MultiLabelBinarizer\nmult=MultiLabelBinarizer()\nda=mult.fit_transform(data)\nda2=pd.DataFrame(da,columns=mult.classes_)\nda2","metadata":{"execution":{"iopub.status.busy":"2024-10-31T06:08:23.482804Z","iopub.execute_input":"2024-10-31T06:08:23.483096Z","iopub.status.idle":"2024-10-31T06:08:23.531445Z","shell.execute_reply.started":"2024-10-31T06:08:23.483066Z","shell.execute_reply":"2024-10-31T06:08:23.530672Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"        Adventure   Animation   Biography   Comedy   Crime   Documentary  \\\n0               0           0           0        0       0             0   \n1               1           0           0        0       0             0   \n2               0           0           0        0       1             0   \n3               0           0           0        0       0             0   \n4               0           0           0        0       0             0   \n...           ...         ...         ...      ...     ...           ...   \n15129           0           0           0        0       1             1   \n15130           0           0           0        0       0             0   \n15131           0           0           0        0       0             0   \n15132           0           0           0        0       0             0   \n15133           0           0           0        0       0             0   \n\n        Drama   Family   Fantasy   Film-Noir  ...  Mystery  Reality-TV  \\\n0           0        0         0           0  ...        0           0   \n1           0        0         0           0  ...        0           0   \n2           0        0         0           0  ...        0           0   \n3           1        0         0           0  ...        0           0   \n4           0        0         0           0  ...        0           0   \n...       ...      ...       ...         ...  ...      ...         ...   \n15129       0        0         0           0  ...        0           0   \n15130       0        0         0           0  ...        0           0   \n15131       0        0         0           0  ...        0           0   \n15132       0        0         0           0  ...        0           1   \n15133       0        0         0           0  ...        0           0   \n\n       Romance  Sci-Fi  Short  Sport  Talk-Show  Thriller  War  Western  \n0            0       0      0      0          0         0    0        0  \n1            0       0      0      0          0         0    0        0  \n2            0       0      0      0          0         0    0        0  \n3            0       0      0      0          0         0    0        0  \n4            0       0      0      0          0         0    0        0  \n...        ...     ...    ...    ...        ...       ...  ...      ...  \n15129        0       0      0      0          0         0    0        0  \n15130        0       0      0      0          0         0    0        0  \n15131        0       0      0      0          0         0    0        0  \n15132        0       0      0      0          0         0    0        0  \n15133        0       0      0      0          0         0    0        0  \n\n[15134 rows x 52 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Adventure</th>\n      <th>Animation</th>\n      <th>Biography</th>\n      <th>Comedy</th>\n      <th>Crime</th>\n      <th>Documentary</th>\n      <th>Drama</th>\n      <th>Family</th>\n      <th>Fantasy</th>\n      <th>Film-Noir</th>\n      <th>...</th>\n      <th>Mystery</th>\n      <th>Reality-TV</th>\n      <th>Romance</th>\n      <th>Sci-Fi</th>\n      <th>Short</th>\n      <th>Sport</th>\n      <th>Talk-Show</th>\n      <th>Thriller</th>\n      <th>War</th>\n      <th>Western</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>15129</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>15130</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>15131</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>15132</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>15133</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>15134 rows × 52 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data1=df2[\"availableCountries\"].str.split(',')\nfrom sklearn.preprocessing import MultiLabelBinarizer\nmult1=MultiLabelBinarizer()\nda1=mult.fit_transform(data1)\nda21=pd.DataFrame(da1,columns=mult.classes_)\nda21","metadata":{"execution":{"iopub.status.busy":"2024-10-31T06:08:23.534404Z","iopub.execute_input":"2024-10-31T06:08:23.534637Z","iopub.status.idle":"2024-10-31T06:08:23.801032Z","shell.execute_reply.started":"2024-10-31T06:08:23.534614Z","shell.execute_reply":"2024-10-31T06:08:23.800267Z"},"trusted":true},"execution_count":43,"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"        AE   AG   AL   AO   AR   AT   AU   AZ   BA   BB  ...  SK  SM  TC  TH  \\\n0        0    0    0    0    0    0    0    0    0    0  ...   0   0   0   0   \n1        0    0    0    0    0    0    0    0    0    0  ...   0   0   0   0   \n2        0    0    1    1    0    1    1    1    0    0  ...   0   0   0   0   \n3        1    1    1    1    1    1    0    1    1    1  ...   0   0   0   0   \n4        0    0    0    0    0    0    0    0    1    0  ...   0   0   0   0   \n...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ..  ..  ..  ..   \n15129    1    1    1    1    1    1    1    1    1    1  ...   0   0   0   0   \n15130    1    1    1    1    1    1    1    1    1    1  ...   0   0   0   0   \n15131    1    0    1    1    1    1    1    1    1    1  ...   0   0   0   0   \n15132    1    0    1    1    1    1    1    1    1    1  ...   0   0   0   0   \n15133    0    0    0    0    0    0    0    0    0    0  ...   0   0   0   0   \n\n       TN  TR  TW  TZ  UA  US  \n0       0   0   0   0   0   0  \n1       0   0   0   0   0   0  \n2       0   0   0   0   0   0  \n3       0   0   0   0   0   0  \n4       0   0   0   0   0   0  \n...    ..  ..  ..  ..  ..  ..  \n15129   0   0   0   0   0   0  \n15130   0   0   0   0   0   0  \n15131   0   0   0   0   0   0  \n15132   0   0   0   0   0   0  \n15133   0   0   0   0   0   0  \n\n[15134 rows x 216 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AE</th>\n      <th>AG</th>\n      <th>AL</th>\n      <th>AO</th>\n      <th>AR</th>\n      <th>AT</th>\n      <th>AU</th>\n      <th>AZ</th>\n      <th>BA</th>\n      <th>BB</th>\n      <th>...</th>\n      <th>SK</th>\n      <th>SM</th>\n      <th>TC</th>\n      <th>TH</th>\n      <th>TN</th>\n      <th>TR</th>\n      <th>TW</th>\n      <th>TZ</th>\n      <th>UA</th>\n      <th>US</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>15129</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>15130</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>15131</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>15132</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>15133</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>15134 rows × 216 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df2.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2024-10-31T06:08:23.802084Z","iopub.execute_input":"2024-10-31T06:08:23.802385Z","iopub.status.idle":"2024-10-31T06:08:23.812135Z","shell.execute_reply.started":"2024-10-31T06:08:23.802354Z","shell.execute_reply":"2024-10-31T06:08:23.811414Z"},"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"title                 0\ntype                  0\ngenres                0\nreleaseYear           0\nimdbAverageRating     0\nimdbNumVotes          0\navailableCountries    0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"concaty=pd.concat([df2,da2,da21],axis=1).drop(columns=[\"genres\",\"availableCountries\"])\nconcaty=concaty.dropna(how='any',axis=0)\nconcaty","metadata":{"execution":{"iopub.status.busy":"2024-10-31T06:08:23.813056Z","iopub.execute_input":"2024-10-31T06:08:23.813327Z","iopub.status.idle":"2024-10-31T06:08:24.023181Z","shell.execute_reply.started":"2024-10-31T06:08:23.813302Z","shell.execute_reply":"2024-10-31T06:08:24.022292Z"},"trusted":true},"execution_count":45,"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"                   title   type  releaseYear  imdbAverageRating  imdbNumVotes  \\\n0           Forrest Gump  movie       1994.0                8.8     2313221.0   \n1      The Fifth Element  movie       1997.0                7.6      516523.0   \n2      Kill Bill: Vol. 1  movie       2003.0                8.2     1220488.0   \n3                Jarhead  movie       2005.0                7.0      211314.0   \n4             Unforgiven  movie       1992.0                8.2      443310.0   \n...                  ...    ...          ...                ...           ...   \n15129        Zombieverse     tv       2023.0                4.4        1108.0   \n15130             Vivant     tv       2023.0                7.0         638.0   \n15131          Miniforce     tv       2014.0                5.0          95.0   \n15132         Full Swing     tv       2023.0                8.0        4333.0   \n15133      At the Moment     tv       2023.0                6.9         427.0   \n\n        Adventure   Animation   Biography   Comedy   Crime  ...   SK   SM  \\\n0             0.0         0.0         0.0      0.0     0.0  ...  0.0  0.0   \n1             1.0         0.0         0.0      0.0     0.0  ...  0.0  0.0   \n2             0.0         0.0         0.0      0.0     1.0  ...  0.0  0.0   \n3             0.0         0.0         0.0      0.0     0.0  ...  0.0  0.0   \n4             0.0         0.0         0.0      0.0     0.0  ...  0.0  0.0   \n...           ...         ...         ...      ...     ...  ...  ...  ...   \n15129         0.0         0.0         0.0      0.0     1.0  ...  0.0  0.0   \n15130         0.0         0.0         0.0      0.0     0.0  ...  0.0  0.0   \n15131         0.0         0.0         0.0      0.0     0.0  ...  0.0  0.0   \n15132         0.0         0.0         0.0      0.0     0.0  ...  0.0  0.0   \n15133         0.0         0.0         0.0      0.0     0.0  ...  0.0  0.0   \n\n        TC   TH   TN   TR   TW   TZ   UA   US  \n0      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n1      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n2      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n3      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n4      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n...    ...  ...  ...  ...  ...  ...  ...  ...  \n15129  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n15130  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n15131  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n15132  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n15133  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n\n[14617 rows x 273 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>type</th>\n      <th>releaseYear</th>\n      <th>imdbAverageRating</th>\n      <th>imdbNumVotes</th>\n      <th>Adventure</th>\n      <th>Animation</th>\n      <th>Biography</th>\n      <th>Comedy</th>\n      <th>Crime</th>\n      <th>...</th>\n      <th>SK</th>\n      <th>SM</th>\n      <th>TC</th>\n      <th>TH</th>\n      <th>TN</th>\n      <th>TR</th>\n      <th>TW</th>\n      <th>TZ</th>\n      <th>UA</th>\n      <th>US</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Forrest Gump</td>\n      <td>movie</td>\n      <td>1994.0</td>\n      <td>8.8</td>\n      <td>2313221.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The Fifth Element</td>\n      <td>movie</td>\n      <td>1997.0</td>\n      <td>7.6</td>\n      <td>516523.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Kill Bill: Vol. 1</td>\n      <td>movie</td>\n      <td>2003.0</td>\n      <td>8.2</td>\n      <td>1220488.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Jarhead</td>\n      <td>movie</td>\n      <td>2005.0</td>\n      <td>7.0</td>\n      <td>211314.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Unforgiven</td>\n      <td>movie</td>\n      <td>1992.0</td>\n      <td>8.2</td>\n      <td>443310.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>15129</th>\n      <td>Zombieverse</td>\n      <td>tv</td>\n      <td>2023.0</td>\n      <td>4.4</td>\n      <td>1108.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>15130</th>\n      <td>Vivant</td>\n      <td>tv</td>\n      <td>2023.0</td>\n      <td>7.0</td>\n      <td>638.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>15131</th>\n      <td>Miniforce</td>\n      <td>tv</td>\n      <td>2014.0</td>\n      <td>5.0</td>\n      <td>95.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>15132</th>\n      <td>Full Swing</td>\n      <td>tv</td>\n      <td>2023.0</td>\n      <td>8.0</td>\n      <td>4333.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>15133</th>\n      <td>At the Moment</td>\n      <td>tv</td>\n      <td>2023.0</td>\n      <td>6.9</td>\n      <td>427.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>14617 rows × 273 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def text_preprocessing(text):\n    if isinstance(text,str):\n        data=text.lower()\n    else:\n        return \"\"\n    data_re=re.sub(r\"\\W+\",\" \",data)\n    data_tokenize=word_tokenize(data_re)\n    tokens=[word for word in data_tokenize if word not in stopwords.words(\"english\")]\n    return \" \".join(tokens)\ndef text_counterizer(text):\n    vectorizer=CountVectorizer()\n    data=text.apply(text_preprocessing)\n    da=vectorizer.fit_transform(data)\n    da=pd.DataFrame(da.toarray(),columns=vectorizer.get_feature_names_out())\n    return da","metadata":{"execution":{"iopub.status.busy":"2024-10-31T06:08:24.024257Z","iopub.execute_input":"2024-10-31T06:08:24.024549Z","iopub.status.idle":"2024-10-31T06:08:24.030299Z","shell.execute_reply.started":"2024-10-31T06:08:24.024519Z","shell.execute_reply":"2024-10-31T06:08:24.029569Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"da=text_counterizer(concaty[\"title\"])","metadata":{"execution":{"iopub.status.busy":"2024-10-31T06:08:24.031223Z","iopub.execute_input":"2024-10-31T06:08:24.031492Z","iopub.status.idle":"2024-10-31T06:08:25.146238Z","shell.execute_reply.started":"2024-10-31T06:08:24.031465Z","shell.execute_reply":"2024-10-31T06:08:25.144777Z"},"trusted":true},"execution_count":47,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)","Cell \u001b[0;32mIn[47], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m da\u001b[38;5;241m=\u001b[39m\u001b[43mtext_counterizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconcaty\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtitle\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[46], line 12\u001b[0m, in \u001b[0;36mtext_counterizer\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtext_counterizer\u001b[39m(text):\n\u001b[1;32m     11\u001b[0m     vectorizer\u001b[38;5;241m=\u001b[39mCountVectorizer()\n\u001b[0;32m---> 12\u001b[0m     data\u001b[38;5;241m=\u001b[39m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_preprocessing\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     da\u001b[38;5;241m=\u001b[39mvectorizer\u001b[38;5;241m.\u001b[39mfit_transform(data)\n\u001b[1;32m     14\u001b[0m     da\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mDataFrame(da\u001b[38;5;241m.\u001b[39mtoarray(),columns\u001b[38;5;241m=\u001b[39mvectorizer\u001b[38;5;241m.\u001b[39mget_feature_names_out())\n","File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4800\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[1;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n","File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n","File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n","Cell \u001b[0;32mIn[46], line 7\u001b[0m, in \u001b[0;36mtext_preprocessing\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m data_re\u001b[38;5;241m=\u001b[39mre\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mW+\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m,data)\n\u001b[0;32m----> 7\u001b[0m data_tokenize\u001b[38;5;241m=\u001b[39m\u001b[43mword_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_re\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m tokens\u001b[38;5;241m=\u001b[39m[word \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m data_tokenize \u001b[38;5;28;01mif\u001b[39;00m word \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m stopwords\u001b[38;5;241m.\u001b[39mwords(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(tokens)\n","File \u001b[0;32m/usr/local/lib/python3.10/site-packages/nltk/tokenize/__init__.py:142\u001b[0m, in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mword_tokenize\u001b[39m(text, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m, preserve_line\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    128\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;124;03m    Return a tokenized copy of *text*,\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;124;03m    using NLTK's recommended word tokenizer\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;124;03m    :type preserve_line: bool\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 142\u001b[0m     sentences \u001b[38;5;241m=\u001b[39m [text] \u001b[38;5;28;01mif\u001b[39;00m preserve_line \u001b[38;5;28;01melse\u001b[39;00m \u001b[43msent_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m    144\u001b[0m         token \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m sentences \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m _treebank_word_tokenizer\u001b[38;5;241m.\u001b[39mtokenize(sent)\n\u001b[1;32m    145\u001b[0m     ]\n","File \u001b[0;32m/usr/local/lib/python3.10/site-packages/nltk/tokenize/__init__.py:119\u001b[0m, in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msent_tokenize\u001b[39m(text, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    110\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;124;03m    Return a sentence-tokenized copy of *text*,\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m    using NLTK's recommended sentence tokenizer\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;124;03m    :param language: the model name in the Punkt corpus\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43m_get_punkt_tokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mtokenize(text)\n","File \u001b[0;32m/usr/local/lib/python3.10/site-packages/nltk/tokenize/__init__.py:105\u001b[0m, in \u001b[0;36m_get_punkt_tokenizer\u001b[0;34m(language)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mlru_cache\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_punkt_tokenizer\u001b[39m(language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     98\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03m    A constructor for the PunktTokenizer that utilizes\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;124;03m    a lru cache for performance.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;124;03m    :type language: str\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPunktTokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/usr/local/lib/python3.10/site-packages/nltk/tokenize/punkt.py:1744\u001b[0m, in \u001b[0;36mPunktTokenizer.__init__\u001b[0;34m(self, lang)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   1743\u001b[0m     PunktSentenceTokenizer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m-> 1744\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_lang\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlang\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/usr/local/lib/python3.10/site-packages/nltk/tokenize/punkt.py:1749\u001b[0m, in \u001b[0;36mPunktTokenizer.load_lang\u001b[0;34m(self, lang)\u001b[0m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_lang\u001b[39m(\u001b[38;5;28mself\u001b[39m, lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   1747\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m find\n\u001b[0;32m-> 1749\u001b[0m     lang_dir \u001b[38;5;241m=\u001b[39m \u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtokenizers/punkt_tab/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlang\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1750\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_params \u001b[38;5;241m=\u001b[39m load_punkt_params(lang_dir)\n\u001b[1;32m   1751\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lang \u001b[38;5;241m=\u001b[39m lang\n","File \u001b[0;32m/usr/local/lib/python3.10/site-packages/nltk/data.py:579\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    577\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[1;32m    578\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 579\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n","\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/local/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"],"ename":"LookupError","evalue":"\n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/local/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n","output_type":"error"}]},{"cell_type":"code","source":"da","metadata":{"execution":{"iopub.status.busy":"2024-10-31T06:08:25.146942Z","iopub.status.idle":"2024-10-31T06:08:25.147244Z","shell.execute_reply.started":"2024-10-31T06:08:25.147096Z","shell.execute_reply":"2024-10-31T06:08:25.147110Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"concaty2=pd.concat([concaty,da],axis=1).drop(columns=[\"title\"])\nconcaty2=concaty2.dropna(how='any',axis=0)\nconcaty2=pd.get_dummies(concaty2).astype(int)\nconcaty2","metadata":{"execution":{"iopub.status.busy":"2024-10-31T06:08:25.148541Z","iopub.status.idle":"2024-10-31T06:08:25.148861Z","shell.execute_reply.started":"2024-10-31T06:08:25.148698Z","shell.execute_reply":"2024-10-31T06:08:25.148712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X=concaty2.drop(columns=[\"imdbAverageRating\"],axis=1)\nY=concaty2[\"imdbAverageRating\"]\n","metadata":{"execution":{"iopub.status.busy":"2024-10-31T06:08:25.149785Z","iopub.status.idle":"2024-10-31T06:08:25.150113Z","shell.execute_reply.started":"2024-10-31T06:08:25.149925Z","shell.execute_reply":"2024-10-31T06:08:25.149939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-10-31T06:08:25.151233Z","iopub.status.idle":"2024-10-31T06:08:25.151566Z","shell.execute_reply.started":"2024-10-31T06:08:25.151403Z","shell.execute_reply":"2024-10-31T06:08:25.151419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape","metadata":{"execution":{"iopub.status.busy":"2024-10-31T06:08:25.152596Z","iopub.status.idle":"2024-10-31T06:08:25.152939Z","shell.execute_reply.started":"2024-10-31T06:08:25.152773Z","shell.execute_reply":"2024-10-31T06:08:25.152789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_train.shape","metadata":{"execution":{"iopub.status.busy":"2024-10-31T06:08:25.153984Z","iopub.status.idle":"2024-10-31T06:08:25.154272Z","shell.execute_reply.started":"2024-10-31T06:08:25.154125Z","shell.execute_reply":"2024-10-31T06:08:25.154138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# allrandom_reg=RandomForestRegressor()\n# random_reg.fit(X_train,Y_train)\n# random_reg.score(X_test,Y_test)","metadata":{"execution":{"iopub.status.busy":"2024-10-31T06:08:25.155399Z","iopub.status.idle":"2024-10-31T06:08:25.155685Z","shell.execute_reply.started":"2024-10-31T06:08:25.155543Z","shell.execute_reply":"2024-10-31T06:08:25.155557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install cirq","metadata":{"execution":{"iopub.status.busy":"2024-10-31T06:08:25.156397Z","iopub.status.idle":"2024-10-31T06:08:25.156667Z","shell.execute_reply.started":"2024-10-31T06:08:25.156533Z","shell.execute_reply":"2024-10-31T06:08:25.156546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cirq","metadata":{"execution":{"iopub.status.busy":"2024-10-31T06:08:25.157707Z","iopub.status.idle":"2024-10-31T06:08:25.158009Z","shell.execute_reply.started":"2024-10-31T06:08:25.157867Z","shell.execute_reply":"2024-10-31T06:08:25.157881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train","metadata":{"execution":{"iopub.status.busy":"2024-10-31T06:08:25.158965Z","iopub.status.idle":"2024-10-31T06:08:25.159248Z","shell.execute_reply.started":"2024-10-31T06:08:25.159105Z","shell.execute_reply":"2024-10-31T06:08:25.159119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def quantum_layer(data):\n    qubit=[cirq.GridQubit(0,i) for i in range(14)]\n    circuit=cirq.Circuit()\n    for i,value in enumerate(data):\n        qubits=qubit[i%len(qubit)]\n        circuit.append(cirq.H(qubits))\n        circuit.append(cirq.rx(value*np.pi).on(qubits))\n        circuit.append(cirq.X(qubits))\n        circuit.append(cirq.ry(value*np.pi).on(qubits))\n        circuit.append(cirq.Y(qubits))\n\n        circuit.append(cirq.rz(value*np.pi).on(qubits))\n        if i%len(qubit)<len(qubit)-1:\n            circuit.append(cirq.CNOT(qubits,qubit[(i+1)%len(qubit)]))\n        circuit.append(cirq.measure(qubits,key=f\"qubit_{i}\"))\n        \n    return circuit, qubit\nX_train2 = np.random.rand(1700)  \ncircuit, qubit = quantum_layer(X_train2)\nprint(circuit)\n# circuit,qubit=quantum_layer(X_train)","metadata":{"execution":{"iopub.status.busy":"2024-10-31T06:08:25.160072Z","iopub.status.idle":"2024-10-31T06:08:25.160356Z","shell.execute_reply.started":"2024-10-31T06:08:25.160210Z","shell.execute_reply":"2024-10-31T06:08:25.160224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install tqdm","metadata":{"execution":{"iopub.status.busy":"2024-10-31T06:08:25.160971Z","iopub.status.idle":"2024-10-31T06:08:25.161282Z","shell.execute_reply.started":"2024-10-31T06:08:25.161109Z","shell.execute_reply":"2024-10-31T06:08:25.161122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.layers import Layer,Dense\nfrom keras.models import Sequential\nimport tensorflow as tf\nfrom tqdm.keras import TqdmCallback","metadata":{"execution":{"iopub.status.busy":"2024-10-31T06:08:25.162372Z","iopub.status.idle":"2024-10-31T06:08:25.162703Z","shell.execute_reply.started":"2024-10-31T06:08:25.162532Z","shell.execute_reply":"2024-10-31T06:08:25.162548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run_quantum_circuit(data):\n    results=[]\n    for inputs_data in data:\n        circuit,qubit=quantum_layer(inputs_data)\n        simulator=cirq.Simulator()\n        result=simulator.run(circuit)\n        measure0=[]\n        for i in range(len(inputs_data)):\n            measure0=result.measurements[f\"qubit_{i}\"].flatten()[0]\n        results.append(measure0)\n    return np.array(results,dtype=np.float32)\nclass QuantumLayer(Layer):\n    def __init__(self):\n        super(QuantumLayer,self).__init__()\n    def call(self,inputs):\n        output=tf.numpy_function(run_quantum_circuit,[inputs],tf.float32)\n        output.set_shape(inputs.shape)\n        return output\nmodel=Sequential([\n    QuantumLayer(),\n    Dense(1)\n])\nmodel.compile(optimizer='adam',loss=\"mse\",metrics=['mae'])","metadata":{"execution":{"iopub.status.busy":"2024-10-31T06:08:25.163479Z","iopub.status.idle":"2024-10-31T06:08:25.163763Z","shell.execute_reply.started":"2024-10-31T06:08:25.163614Z","shell.execute_reply":"2024-10-31T06:08:25.163628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(X_train.iloc[:10,:],Y_train[:10],callbacks=[TqdmCallback(verbose=1)])","metadata":{"execution":{"iopub.status.busy":"2024-10-31T06:08:25.164889Z","iopub.status.idle":"2024-10-31T06:08:25.165170Z","shell.execute_reply.started":"2024-10-31T06:08:25.165031Z","shell.execute_reply":"2024-10-31T06:08:25.165045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install qiskit[all]","metadata":{"execution":{"iopub.status.busy":"2024-10-31T06:14:30.127959Z","iopub.execute_input":"2024-10-31T06:14:30.128329Z","iopub.status.idle":"2024-10-31T06:14:40.438896Z","shell.execute_reply.started":"2024-10-31T06:14:30.128298Z","shell.execute_reply":"2024-10-31T06:14:40.437724Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"Requirement already satisfied: qiskit[all] in /usr/local/lib/python3.10/site-packages (1.2.4)\nRequirement already satisfied: sympy>=1.3 in /usr/local/lib/python3.10/site-packages (from qiskit[all]) (1.13.3)\nRequirement already satisfied: dill>=0.3 in /usr/local/lib/python3.10/site-packages (from qiskit[all]) (0.3.9)\nRequirement already satisfied: rustworkx>=0.15.0 in /usr/local/lib/python3.10/site-packages (from qiskit[all]) (0.15.1)\nRequirement already satisfied: symengine<0.14,>=0.11 in /usr/local/lib/python3.10/site-packages (from qiskit[all]) (0.13.0)\nRequirement already satisfied: stevedore>=3.0.0 in /usr/local/lib/python3.10/site-packages (from qiskit[all]) (5.3.0)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/site-packages (from qiskit[all]) (4.12.2)\nRequirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.10/site-packages (from qiskit[all]) (1.14.1)\nRequirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.10/site-packages (from qiskit[all]) (2.9.0.post0)\nRequirement already satisfied: numpy<3,>=1.17 in /usr/local/lib/python3.10/site-packages (from qiskit[all]) (1.26.4)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil>=2.8.0->qiskit[all]) (1.16.0)\nRequirement already satisfied: pbr>=2.0.0 in /usr/local/lib/python3.10/site-packages (from stevedore>=3.0.0->qiskit[all]) (6.1.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/site-packages (from sympy>=1.3->qiskit[all]) (1.3.0)\nCollecting python-constraint>=1.4\n  Downloading python-constraint-1.4.0.tar.bz2 (18 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.10/site-packages (from qiskit[all]) (3.9.2)\nCollecting pylatexenc>=1.4\n  Downloading pylatexenc-2.10.tar.gz (162 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: Pillow>=4.2.1 in /usr/local/lib/python3.10/site-packages (from qiskit[all]) (10.4.0)\nRequirement already satisfied: seaborn>=0.9.0 in /usr/local/lib/python3.10/site-packages (from qiskit[all]) (0.13.2)\nCollecting pydot\n  Downloading pydot-3.0.2-py3-none-any.whl (35 kB)\nCollecting qiskit-qasm3-import>=0.1.0\n  Downloading qiskit_qasm3_import-0.5.0-py3-none-any.whl (27 kB)\nCollecting z3-solver>=4.7\n  Downloading z3_solver-4.13.3.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.1/28.1 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/site-packages (from matplotlib>=3.3->qiskit[all]) (0.12.1)\nRequirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib>=3.3->qiskit[all]) (1.4.7)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from matplotlib>=3.3->qiskit[all]) (23.2)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib>=3.3->qiskit[all]) (3.1.4)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/site-packages (from matplotlib>=3.3->qiskit[all]) (4.54.1)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/site-packages (from matplotlib>=3.3->qiskit[all]) (1.3.0)\nCollecting openqasm3[parser]<0.6,>=0.4\n  Downloading openqasm3-0.5.0-py3-none-any.whl (524 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m524.0/524.0 kB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.10/site-packages (from seaborn>=0.9.0->qiskit[all]) (2.2.3)\nCollecting antlr4-python3-runtime<4.14,>=4.7\n  Downloading antlr4_python3_runtime-4.13.2-py3-none-any.whl (144 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.5/144.5 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/site-packages (from pandas>=1.2->seaborn>=0.9.0->qiskit[all]) (2024.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/site-packages (from pandas>=1.2->seaborn>=0.9.0->qiskit[all]) (2024.2)\nBuilding wheels for collected packages: pylatexenc, python-constraint\n  Building wheel for pylatexenc (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pylatexenc: filename=pylatexenc-2.10-py3-none-any.whl size=136818 sha256=b893135e91a58ce0c9b3fa240003a5dc3b12ef1a5b12455f123332b67623c2cf\n  Stored in directory: /root/.cache/pip/wheels/d3/31/8b/e09b0386afd80cfc556c00408c9aeea5c35c4d484a9c762fd5\n  Building wheel for python-constraint (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for python-constraint: filename=python_constraint-1.4.0-py2.py3-none-any.whl size=24059 sha256=ee6ba89f8a7668dba0ff4e868f9c7134aeea6cee1ed70f57d037626aaee074ba\n  Stored in directory: /root/.cache/pip/wheels/2e/f2/2b/cb08b5fe129e4f69b7033061f256e5c551b0aa1160c2872aee\nSuccessfully built pylatexenc python-constraint\nInstalling collected packages: z3-solver, python-constraint, pylatexenc, openqasm3, antlr4-python3-runtime, pydot, qiskit-qasm3-import\nSuccessfully installed antlr4-python3-runtime-4.13.2 openqasm3-0.5.0 pydot-3.0.2 pylatexenc-2.10 python-constraint-1.4.0 qiskit-qasm3-import-0.5.0 z3-solver-4.13.3.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"# from qiskit import QuantumCircuit\n# from qiskit import execute\n# from qiskit.providers.ibmq import IBMQ\n# def quantum_layer(data):\n#     qubit=14\n#     circuit=QuantumCircuit(14)\n#     for i,value in enumerate(data):\n#         qubits=i%qubit\n#         circuit.h(qubits)\n#         circuit.rx(value*np.pi,qubits)\n#         circuit.x(qubits)\n#         circuit.ry(value*np.pi,qubits)\n#         circuit.y(qubits)\n\n#         circuit.rz(value*np.pi,qubits)\n#         if i<qubits-1:\n#             circuit.cx(qubits,(qubits+1)%qubits)\n#         circuit.measure_all()\n        \n#     return circuit\n\n# def run_quantum_circuit(data): \n#     results=[]\n#     for inputs_data in data:\n#         circuit=quantum_layer(inputs_data)\n#         provider=IBQM.get_provider().get_backend(\"ibmq_qasm_simulator\")\n#         jobs=execute(circuit,backend=provider,shots=1234)\n#         results=jobs.results\n#         counts=results.get_counts(circuit)\n#         measure0=[]\n#         for i in range(len(inputs_data)):\n#             binary_representation=bit(i)[2:].zfill(14)\n#             measure0=counts.get(binary_representation,0)\n#         results.append(measure0)\n#     return np.array(results,dtypes=np.float32)\n# class QuantumLayer(Layer):\n#     def __init__(self):\n#         super(QuantumLayer,self).__init__()\n#     def call(self,inputs):\n#         output=tf.numpy_function(run_quantum_circuit,[inputs],tf.float32)\n#         output.set_shape(inputs.shape)\n#         return output\n# model=Sequential([\n#     QuantumLayer(),\n#     Dense(1)\n# ])\n# model.compile(optimizer='adam',loss=\"mse\",metrics=['mae'])\n","metadata":{"execution":{"iopub.status.busy":"2024-10-31T06:14:42.967836Z","iopub.execute_input":"2024-10-31T06:14:42.968239Z","iopub.status.idle":"2024-10-31T06:14:43.030001Z","shell.execute_reply.started":"2024-10-31T06:14:42.968203Z","shell.execute_reply":"2024-10-31T06:14:43.028992Z"},"trusted":true},"execution_count":53,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","Cell \u001b[0;32mIn[53], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mqiskit\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m QuantumCircuit\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mqiskit\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m execute\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mqiskit\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mproviders\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mibmq\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IBMQ\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mquantum_layer\u001b[39m(data):\n","\u001b[0;31mImportError\u001b[0m: cannot import name 'execute' from 'qiskit' (/usr/local/lib/python3.10/site-packages/qiskit/__init__.py)"],"ename":"ImportError","evalue":"cannot import name 'execute' from 'qiskit' (/usr/local/lib/python3.10/site-packages/qiskit/__init__.py)","output_type":"error"}]},{"cell_type":"code","source":"# from qiskit import QuantumCircuit, Aer\n# from qiskit.execute import execute\n# from qiskit.providers.ibmq import IBMQ\n","metadata":{"execution":{"iopub.status.busy":"2024-10-31T06:17:00.071383Z","iopub.execute_input":"2024-10-31T06:17:00.071770Z","iopub.status.idle":"2024-10-31T06:17:00.075240Z","shell.execute_reply.started":"2024-10-31T06:17:00.071724Z","shell.execute_reply":"2024-10-31T06:17:00.074540Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}