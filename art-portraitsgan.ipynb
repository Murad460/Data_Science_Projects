{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7457578,"sourceType":"datasetVersion","datasetId":1698586}],"dockerImageVersionId":30775,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os,cv2\nfrom keras.utils import image_dataset_from_directory\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-04T03:54:06.520315Z","iopub.execute_input":"2024-10-04T03:54:06.520911Z","iopub.status.idle":"2024-10-04T03:54:23.020196Z","shell.execute_reply.started":"2024-10-04T03:54:06.520855Z","shell.execute_reply":"2024-10-04T03:54:23.018847Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"df=\"/kaggle/input/art-portraits/Portraits_update/Portraits\"\ndf2=\"/kaggle/input/art-portraits/Portraits_update\"","metadata":{"execution":{"iopub.status.busy":"2024-10-04T03:54:23.022977Z","iopub.execute_input":"2024-10-04T03:54:23.023865Z","iopub.status.idle":"2024-10-04T03:54:23.030644Z","shell.execute_reply.started":"2024-10-04T03:54:23.023800Z","shell.execute_reply":"2024-10-04T03:54:23.029171Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"new_img=[]\nfor file in os.listdir(df):\n    data=os.path.join(df,file)\n    cv=cv2.imread(data)\n    if cv is not None:\n        cv_resize=cv2.resize(cv,(256,256))\n        new_img.append(cv_resize)\nnew_img=np.array(new_img)","metadata":{"execution":{"iopub.status.busy":"2024-10-04T03:54:23.032576Z","iopub.execute_input":"2024-10-04T03:54:23.033995Z","iopub.status.idle":"2024-10-04T03:56:20.237291Z","shell.execute_reply.started":"2024-10-04T03:54:23.033933Z","shell.execute_reply":"2024-10-04T03:56:20.235780Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"new_img.shape","metadata":{"execution":{"iopub.status.busy":"2024-10-04T03:56:20.239221Z","iopub.execute_input":"2024-10-04T03:56:20.239633Z","iopub.status.idle":"2024-10-04T03:56:20.249246Z","shell.execute_reply.started":"2024-10-04T03:56:20.239591Z","shell.execute_reply":"2024-10-04T03:56:20.247894Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"(6510, 256, 256, 3)"},"metadata":{}}]},{"cell_type":"code","source":"datagen=ImageDataGenerator(\nrotation_range=42\n)\ntarget_img=datagen.flow_from_directory(\ndf2,\ntarget_size=(256,256),\nbatch_size=32,\nclass_mode=None,\nshuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-10-04T03:56:20.252705Z","iopub.execute_input":"2024-10-04T03:56:20.253263Z","iopub.status.idle":"2024-10-04T03:56:21.705635Z","shell.execute_reply.started":"2024-10-04T03:56:20.253207Z","shell.execute_reply":"2024-10-04T03:56:21.704622Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Found 6512 images belonging to 1 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"for i in target_img:\n    print(i.shape)\n    break","metadata":{"execution":{"iopub.status.busy":"2024-10-04T03:56:21.707371Z","iopub.execute_input":"2024-10-04T03:56:21.707831Z","iopub.status.idle":"2024-10-04T03:56:22.937934Z","shell.execute_reply.started":"2024-10-04T03:56:21.707708Z","shell.execute_reply":"2024-10-04T03:56:22.936453Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"(32, 256, 256, 3)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# # GAN","metadata":{}},{"cell_type":"code","source":"from keras.layers import Dense,Flatten,Conv2D,MaxPooling2D,Conv2DTranspose,Input,UpSampling2D,BatchNormalization,Reshape,ReLU\nfrom keras.models import Model\n","metadata":{"execution":{"iopub.status.busy":"2024-10-04T04:04:30.379268Z","iopub.execute_input":"2024-10-04T04:04:30.380278Z","iopub.status.idle":"2024-10-04T04:04:30.387264Z","shell.execute_reply.started":"2024-10-04T04:04:30.380222Z","shell.execute_reply":"2024-10-04T04:04:30.385815Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, Reshape, Conv2D, Conv2DTranspose, BatchNormalization, UpSampling2D, LeakyReLU, Flatten, Input\nfrom tensorflow.keras.optimizers import Adam\n\n# Build the generator model\ndef build_generator():\n    inputs = Input(shape=(100,))\n    C = Dense(8*8*256)(inputs)\n    C = Reshape((8, 8, 256))(C)\n    \n    C = Conv2DTranspose(256, (3,3), strides=(4,4), padding='same', activation='relu')(C)\n    C = BatchNormalization()(C)\n    \n    C = Conv2DTranspose(128, (3,3), strides=(2,2), padding='same', activation='relu')(C)\n    C = BatchNormalization()(C)\n    \n    C = Conv2DTranspose(64, (3,3), strides=(2,2), padding='same', activation='relu')(C)\n    C = BatchNormalization()(C)\n    \n    C = Conv2DTranspose(3, (3,3), strides=(2,2), padding='same', activation='sigmoid')(C)\n    \n    model = Model(inputs, C)\n    return model\n\n# Build the discriminator model\ndef build_discriminator():\n    inputs = Input(shape=(256, 256, 3))\n    \n    C = Conv2D(64, (3,3), strides=(2,2), padding='same')(inputs)\n    C = LeakyReLU(alpha=0.2)(C)\n    \n    C = Conv2D(128, (3,3), strides=(2,2), padding='same')(C)\n    C = LeakyReLU(alpha=0.2)(C)\n    C = BatchNormalization()(C)\n    \n    C = Conv2D(256, (3,3), strides=(2,2), padding='same')(C)\n    C = LeakyReLU(alpha=0.2)(C)\n    C = BatchNormalization()(C)\n    \n    C = Flatten()(C)\n    C = Dense(1, activation='sigmoid')(C)\n    \n    model = Model(inputs, C)\n    return model\n\ndef build_gan(generator, discriminator):\n    discriminator.trainable = False\n    gan_input = Input(shape=(100,))\n    fake_img = generator(gan_input)\n    gan_output = discriminator(fake_img)\n    \n    model = Model(gan_input, gan_output)\n    return model\n\n# Training function\ndef train_model(gan, generator, discriminator, epochs, batch_size, dataset):\n    discriminator.trainable = True\n    discriminator.compile(optimizer=Adam(0.0002, 0.5), loss='binary_crossentropy', metrics=['accuracy'])\n    \n    gan.compile(optimizer=Adam(0.0002, 0.5), loss='binary_crossentropy')\n\n    for epoch in range(epochs):\n        print(f\"Epoch {epoch+1}/{epochs}\")\n\n        for real_img in dataset:\n            if real_img.shape[0] != batch_size:\n                continue\n\n            real_label = np.ones((batch_size, 1))\n            fake_label = np.zeros((batch_size, 1))\n\n            noise = np.random.normal(0, 1, (batch_size, 100))\n            fake_img = generator.predict(noise)\n\n            discriminator.trainable = True\n            d_loss_real = discriminator.train_on_batch(real_img, real_label)\n            d_loss_fake = discriminator.train_on_batch(fake_img, fake_label)\n\n            noise = np.random.normal(0, 1, (batch_size, 100))\n            gan_labels = np.ones((batch_size, 1)) \n            discriminator.trainable = False\n            g_loss = gan.train_on_batch(noise, gan_labels)\n\n        print(f\"Discriminator loss (real/fake): {d_loss_real[0]:.4f} / {d_loss_fake[0]:.4f} | Generator loss: {g_loss:.4f}\")\n\n    return gan\n\n# Instantiate the models\ngenerator = build_generator()\ndiscriminator = build_discriminator()\ngan = build_gan(generator, discriminator)\n\ngan = train_model(gan, generator, discriminator, epochs=2, batch_size=32, dataset=target_img)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-04T04:37:38.301127Z","iopub.execute_input":"2024-10-04T04:37:38.301664Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/2\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 808ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 677ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 674ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 678ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 678ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 678ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 793ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 662ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 667ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 670ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 681ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 672ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 687ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 691ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 840ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 669ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 829ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"t=np.expand_dims(target_img[0],axis=0)\ngan.predict(t)","metadata":{"execution":{"iopub.status.busy":"2024-10-04T04:37:35.711436Z","iopub.status.idle":"2024-10-04T04:37:35.712202Z","shell.execute_reply.started":"2024-10-04T04:37:35.711819Z","shell.execute_reply":"2024-10-04T04:37:35.711855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}