{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.cluster import KMeans\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-17T04:10:16.700759Z","iopub.execute_input":"2024-09-17T04:10:16.701217Z","iopub.status.idle":"2024-09-17T04:10:16.707691Z","shell.execute_reply.started":"2024-09-17T04:10:16.701172Z","shell.execute_reply":"2024-09-17T04:10:16.706380Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv(\"/kaggle/input/heart-attack-analysis-prediction-dataset/heart.csv\")\ndf_sat=pd.read_csv(\"/kaggle/input/heart-attack-analysis-prediction-dataset/o2Saturation.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-09-17T04:02:45.560616Z","iopub.execute_input":"2024-09-17T04:02:45.561079Z","iopub.status.idle":"2024-09-17T04:02:45.649739Z","shell.execute_reply.started":"2024-09-17T04:02:45.561031Z","shell.execute_reply":"2024-09-17T04:02:45.648346Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"df.head(10)","metadata":{"execution":{"iopub.status.busy":"2024-09-17T04:02:45.652099Z","iopub.execute_input":"2024-09-17T04:02:45.652521Z","iopub.status.idle":"2024-09-17T04:02:45.673866Z","shell.execute_reply.started":"2024-09-17T04:02:45.652479Z","shell.execute_reply":"2024-09-17T04:02:45.672370Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"   age  sex  cp  trtbps  chol  fbs  restecg  thalachh  exng  oldpeak  slp  \\\n0   63    1   3     145   233    1        0       150     0      2.3    0   \n1   37    1   2     130   250    0        1       187     0      3.5    0   \n2   41    0   1     130   204    0        0       172     0      1.4    2   \n3   56    1   1     120   236    0        1       178     0      0.8    2   \n4   57    0   0     120   354    0        1       163     1      0.6    2   \n5   57    1   0     140   192    0        1       148     0      0.4    1   \n6   56    0   1     140   294    0        0       153     0      1.3    1   \n7   44    1   1     120   263    0        1       173     0      0.0    2   \n8   52    1   2     172   199    1        1       162     0      0.5    2   \n9   57    1   2     150   168    0        1       174     0      1.6    2   \n\n   caa  thall  output  \n0    0      1       1  \n1    0      2       1  \n2    0      2       1  \n3    0      2       1  \n4    0      2       1  \n5    0      1       1  \n6    0      2       1  \n7    0      3       1  \n8    0      3       1  \n9    0      2       1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>sex</th>\n      <th>cp</th>\n      <th>trtbps</th>\n      <th>chol</th>\n      <th>fbs</th>\n      <th>restecg</th>\n      <th>thalachh</th>\n      <th>exng</th>\n      <th>oldpeak</th>\n      <th>slp</th>\n      <th>caa</th>\n      <th>thall</th>\n      <th>output</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>63</td>\n      <td>1</td>\n      <td>3</td>\n      <td>145</td>\n      <td>233</td>\n      <td>1</td>\n      <td>0</td>\n      <td>150</td>\n      <td>0</td>\n      <td>2.3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>37</td>\n      <td>1</td>\n      <td>2</td>\n      <td>130</td>\n      <td>250</td>\n      <td>0</td>\n      <td>1</td>\n      <td>187</td>\n      <td>0</td>\n      <td>3.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>41</td>\n      <td>0</td>\n      <td>1</td>\n      <td>130</td>\n      <td>204</td>\n      <td>0</td>\n      <td>0</td>\n      <td>172</td>\n      <td>0</td>\n      <td>1.4</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>56</td>\n      <td>1</td>\n      <td>1</td>\n      <td>120</td>\n      <td>236</td>\n      <td>0</td>\n      <td>1</td>\n      <td>178</td>\n      <td>0</td>\n      <td>0.8</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>57</td>\n      <td>0</td>\n      <td>0</td>\n      <td>120</td>\n      <td>354</td>\n      <td>0</td>\n      <td>1</td>\n      <td>163</td>\n      <td>1</td>\n      <td>0.6</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>57</td>\n      <td>1</td>\n      <td>0</td>\n      <td>140</td>\n      <td>192</td>\n      <td>0</td>\n      <td>1</td>\n      <td>148</td>\n      <td>0</td>\n      <td>0.4</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>56</td>\n      <td>0</td>\n      <td>1</td>\n      <td>140</td>\n      <td>294</td>\n      <td>0</td>\n      <td>0</td>\n      <td>153</td>\n      <td>0</td>\n      <td>1.3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>44</td>\n      <td>1</td>\n      <td>1</td>\n      <td>120</td>\n      <td>263</td>\n      <td>0</td>\n      <td>1</td>\n      <td>173</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>52</td>\n      <td>1</td>\n      <td>2</td>\n      <td>172</td>\n      <td>199</td>\n      <td>1</td>\n      <td>1</td>\n      <td>162</td>\n      <td>0</td>\n      <td>0.5</td>\n      <td>2</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>57</td>\n      <td>1</td>\n      <td>2</td>\n      <td>150</td>\n      <td>168</td>\n      <td>0</td>\n      <td>1</td>\n      <td>174</td>\n      <td>0</td>\n      <td>1.6</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# df2=df.drop(columns=[\"output\"])\n# df2.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2024-09-17T04:03:20.828412Z","iopub.execute_input":"2024-09-17T04:03:20.829259Z","iopub.status.idle":"2024-09-17T04:03:20.833776Z","shell.execute_reply.started":"2024-09-17T04:03:20.829199Z","shell.execute_reply":"2024-09-17T04:03:20.832563Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# df2.shape","metadata":{"execution":{"iopub.status.busy":"2024-09-17T04:02:45.691272Z","iopub.execute_input":"2024-09-17T04:02:45.691718Z","iopub.status.idle":"2024-09-17T04:02:45.707060Z","shell.execute_reply.started":"2024-09-17T04:02:45.691673Z","shell.execute_reply":"2024-09-17T04:02:45.705683Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"(303, 13)"},"metadata":{}}]},{"cell_type":"code","source":"km=KMeans(n_clusters=2)\nkm.fit(df)\nkm.labels_","metadata":{"execution":{"iopub.status.busy":"2024-09-17T04:03:47.691567Z","iopub.execute_input":"2024-09-17T04:03:47.692040Z","iopub.status.idle":"2024-09-17T04:03:47.733028Z","shell.execute_reply.started":"2024-09-17T04:03:47.691995Z","shell.execute_reply":"2024-09-17T04:03:47.731995Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  warnings.warn(\n","output_type":"stream"},{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"array([1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n       1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0,\n       0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n       1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n       0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0,\n       0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n       1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1,\n       0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1,\n       0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n       1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0,\n       1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0,\n       1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1], dtype=int32)"},"metadata":{}}]},{"cell_type":"code","source":"from tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Dense, Dropout\n\n# Define the dimensions\ninput_dim = df2.shape[1]  # Number of features in the dataset\nencoding_dim = 64  # Latent space representation\n\n# Input layer\ninput_layer = Input(shape=(input_dim,))\n\n# Encoder: Increase the number of layers\nencoded = Dense(128, activation='relu')(input_layer)\nencoded = Dense(64, activation='relu')(encoded)\nencoded = Dense(encoding_dim, activation='relu')(encoded)\n\n# Decoder: Increase the number of layers\ndecoded = Dense(64, activation='relu')(encoded)\ndecoded = Dense(128, activation='relu')(decoded)\ndecoded = Dense(input_dim, activation='sigmoid')(decoded)\n\n# Autoencoder model\nautoencoder = Model(inputs=input_layer, outputs=decoded)\n\n# Compile the model\nautoencoder.compile(optimizer='adam', loss='mse')\n\n# Train the autoencoder\nautoencoder.fit(df2,df2, epochs=50, batch_size=256, shuffle=True, validation_split=0.2)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-17T04:02:45.750155Z","iopub.execute_input":"2024-09-17T04:02:45.751500Z","iopub.status.idle":"2024-09-17T04:02:50.923083Z","shell.execute_reply.started":"2024-09-17T04:02:45.751436Z","shell.execute_reply":"2024-09-17T04:02:50.921813Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Epoch 1/50\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 8300.5820 - val_loss: 7896.2036\nEpoch 2/50\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 8277.7969 - val_loss: 7868.6450\nEpoch 3/50\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 8248.3770 - val_loss: 7859.5522\nEpoch 4/50\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 8240.6611 - val_loss: 7859.4487\nEpoch 5/50\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 8240.5967 - val_loss: 7859.4463\nEpoch 6/50\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 8240.5967 - val_loss: 7859.4419\nEpoch 7/50\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 8240.5947 - val_loss: 7859.4302\nEpoch 8/50\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 8240.5889 - val_loss: 7859.4077\nEpoch 9/50\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 8240.5771 - val_loss: 7859.3643\nEpoch 10/50\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 8240.5537 - val_loss: 7859.2827\nEpoch 11/50\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 8240.5098 - val_loss: 7859.1230\nEpoch 12/50\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 8240.4150 - val_loss: 7858.6519\nEpoch 13/50\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 8240.1260 - val_loss: 7856.4868\nEpoch 14/50\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 8238.5615 - val_loss: 7845.0596\nEpoch 15/50\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 8227.6680 - val_loss: 7838.6753\nEpoch 16/50\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 8220.4697 - val_loss: 7838.0977\nEpoch 17/50\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 8219.9258 - val_loss: 7834.8589\nEpoch 18/50\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 8216.7090 - val_loss: 7830.3828\nEpoch 19/50\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 8212.4258 - val_loss: 7830.1494\nEpoch 20/50\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 8212.2637 - val_loss: 7830.1328\nEpoch 21/50\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 8212.2510 - val_loss: 7830.1289\nEpoch 22/50\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 8212.2402 - val_loss: 7830.1401\nEpoch 23/50\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 8212.2314 - val_loss: 7830.1772\nEpoch 24/50\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 8212.2354 - val_loss: 7830.1943\nEpoch 25/50\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 8212.2393 - val_loss: 7830.2021\nEpoch 26/50\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 8212.2402 - val_loss: 7830.2026\nEpoch 27/50\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 8212.2383 - val_loss: 7830.1870\nEpoch 28/50\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 8212.2285 - val_loss: 7830.1519\nEpoch 29/50\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 8212.2021 - val_loss: 7830.0996\nEpoch 30/50\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 8212.1572 - val_loss: 7830.0518\nEpoch 31/50\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 8212.1104 - val_loss: 7830.0288\nEpoch 32/50\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 8212.0918 - val_loss: 7830.0195\nEpoch 33/50\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 8212.0898 - val_loss: 7830.0171\nEpoch 34/50\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 8212.0908 - val_loss: 7830.0166\nEpoch 35/50\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 8212.0908 - val_loss: 7830.0186\nEpoch 36/50\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 8212.0898 - val_loss: 7830.0244\nEpoch 37/50\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 8212.0869 - val_loss: 7830.0356\nEpoch 38/50\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 8212.0850 - val_loss: 7830.0542\nEpoch 39/50\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 8212.0850 - val_loss: 7830.0664\nEpoch 40/50\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 8212.0879 - val_loss: 7830.0654\nEpoch 41/50\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 8212.0869 - val_loss: 7830.0552\nEpoch 42/50\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 8212.0850 - val_loss: 7830.0410\nEpoch 43/50\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 8212.0840 - val_loss: 7830.0308\nEpoch 44/50\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 8212.0850 - val_loss: 7830.0264\nEpoch 45/50\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 8212.0859 - val_loss: 7830.0249\nEpoch 46/50\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 8212.0859 - val_loss: 7830.0288\nEpoch 47/50\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 8212.0850 - val_loss: 7830.0352\nEpoch 48/50\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 8212.0840 - val_loss: 7830.0435\nEpoch 49/50\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 8212.0840 - val_loss: 7830.0493\nEpoch 50/50\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 8212.0840 - val_loss: 7830.0513\n","output_type":"stream"},{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7a587436fe50>"},"metadata":{}}]},{"cell_type":"code","source":"X=df.drop(columns=[\"output\"])\nY=df[\"output\"]","metadata":{"execution":{"iopub.status.busy":"2024-09-17T04:07:43.770859Z","iopub.execute_input":"2024-09-17T04:07:43.771323Z","iopub.status.idle":"2024-09-17T04:07:43.777675Z","shell.execute_reply.started":"2024-09-17T04:07:43.771277Z","shell.execute_reply":"2024-09-17T04:07:43.776706Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-09-17T04:07:44.890062Z","iopub.execute_input":"2024-09-17T04:07:44.890552Z","iopub.status.idle":"2024-09-17T04:07:44.900199Z","shell.execute_reply.started":"2024-09-17T04:07:44.890501Z","shell.execute_reply":"2024-09-17T04:07:44.898657Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"random_classif=RandomForestClassifier()\nrandom_classif.fit(X_train,Y_train)\nrandom_classif.score(X_test,Y_test)","metadata":{"execution":{"iopub.status.busy":"2024-09-17T04:08:26.399720Z","iopub.execute_input":"2024-09-17T04:08:26.400205Z","iopub.status.idle":"2024-09-17T04:08:26.661013Z","shell.execute_reply.started":"2024-09-17T04:08:26.400132Z","shell.execute_reply":"2024-09-17T04:08:26.659777Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"0.8524590163934426"},"metadata":{}}]},{"cell_type":"code","source":"log_classif=LogisticRegression()\nlog_classif.fit(X_train,Y_train)\nlog_classif.score(X_test,Y_test)","metadata":{"execution":{"iopub.status.busy":"2024-09-17T04:09:18.936202Z","iopub.execute_input":"2024-09-17T04:09:18.936669Z","iopub.status.idle":"2024-09-17T04:09:18.985352Z","shell.execute_reply.started":"2024-09-17T04:09:18.936625Z","shell.execute_reply":"2024-09-17T04:09:18.984034Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"},{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"0.8852459016393442"},"metadata":{}}]},{"cell_type":"code","source":"grad_classif=GradientBoostingClassifier()\ngrad_classif.fit(X_train,Y_train)\n\ngrad_classif.score(X_test,Y_test)","metadata":{"execution":{"iopub.status.busy":"2024-09-17T04:10:22.558709Z","iopub.execute_input":"2024-09-17T04:10:22.559179Z","iopub.status.idle":"2024-09-17T04:10:22.707521Z","shell.execute_reply.started":"2024-09-17T04:10:22.559128Z","shell.execute_reply":"2024-09-17T04:10:22.706316Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"0.7704918032786885"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# # Deep learning","metadata":{}},{"cell_type":"code","source":"from keras.layers import Dense,Dropout,BatchNormalization,Input\nfrom keras.models import Model\nfrom keras.initializers import HeNormal\nfrom keras.regularizers import l2\nfrom keras.callbacks import EarlyStopping","metadata":{"execution":{"iopub.status.busy":"2024-09-17T04:13:17.400639Z","iopub.execute_input":"2024-09-17T04:13:17.401113Z","iopub.status.idle":"2024-09-17T04:13:17.410808Z","shell.execute_reply.started":"2024-09-17T04:13:17.401066Z","shell.execute_reply":"2024-09-17T04:13:17.409685Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"early_stopping=EarlyStopping(\nmonitor='val_loss',\npatience=5,\nverbose=1)","metadata":{"execution":{"iopub.status.busy":"2024-09-17T04:13:51.100023Z","iopub.execute_input":"2024-09-17T04:13:51.100503Z","iopub.status.idle":"2024-09-17T04:13:51.108367Z","shell.execute_reply.started":"2024-09-17T04:13:51.100461Z","shell.execute_reply":"2024-09-17T04:13:51.106118Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"X_train.shape","metadata":{"execution":{"iopub.status.busy":"2024-09-17T04:14:20.103285Z","iopub.execute_input":"2024-09-17T04:14:20.103793Z","iopub.status.idle":"2024-09-17T04:14:20.112988Z","shell.execute_reply.started":"2024-09-17T04:14:20.103747Z","shell.execute_reply":"2024-09-17T04:14:20.111609Z"},"trusted":true},"execution_count":45,"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"(242, 13)"},"metadata":{}}]},{"cell_type":"code","source":"inputs=Input(shape=(13,))\nD=Dense(64,activation=\"relu\",kernel_initializer=HeNormal(),kernel_regularizer=l2(0.01))(inputs)\nD=Dense(64,activation=\"relu\",kernel_initializer=HeNormal(),kernel_regularizer=l2(0.01))(D)\n\n# D=Dense(32,activation=\"relu\",kernel_initializer=HeNormal(),kernel_regularizer=l2(0.01))(D)\nB=BatchNormalization()(D)\nD=Dropout(0.5)(B)\nD=Dense(32,activation=\"relu\",kernel_initializer=HeNormal(),kernel_regularizer=l2(0.01))(D)\n\nD=Dense(32,activation=\"relu\",kernel_initializer=HeNormal(),kernel_regularizer=l2(0.01))(D)\n# D=Dense(64,activation=\"relu\",kernel_initializer=HeNormal(),kernel_regularizer=l2(0.01))(D)\nB=BatchNormalization()(D)\noutputs=Dense(1,activation=\"softmax\")(B)\nmodel=Model(inputs,outputs)\nmodel.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-09-17T04:21:23.919273Z","iopub.execute_input":"2024-09-17T04:21:23.919849Z","iopub.status.idle":"2024-09-17T04:21:24.015161Z","shell.execute_reply.started":"2024-09-17T04:21:23.919782Z","shell.execute_reply":"2024-09-17T04:21:24.013793Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"model.fit(X_train,Y_train,epochs=50,batch_size=32,validation_data=(X_test,Y_test),callbacks=[early_stopping])","metadata":{"execution":{"iopub.status.busy":"2024-09-17T04:21:24.684701Z","iopub.execute_input":"2024-09-17T04:21:24.685165Z","iopub.status.idle":"2024-09-17T04:21:28.470668Z","shell.execute_reply.started":"2024-09-17T04:21:24.685102Z","shell.execute_reply":"2024-09-17T04:21:28.469221Z"},"trusted":true},"execution_count":57,"outputs":[{"name":"stdout","text":"Epoch 1/50\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis -1 of a tensor of shape (None, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.5364 - loss: 4.7228 - val_accuracy: 0.5246 - val_loss: 6.1335\nEpoch 2/50\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis -1 of a tensor of shape (None, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5569 - loss: 4.5998 - val_accuracy: 0.5246 - val_loss: 6.3355\nEpoch 3/50\n\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5066 - loss: 4.4314 - val_accuracy: 0.5246 - val_loss: 6.9213\nEpoch 4/50\n\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5394 - loss: 4.2309 - val_accuracy: 0.5246 - val_loss: 6.7717\nEpoch 5/50\n\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5487 - loss: 4.0541 - val_accuracy: 0.5246 - val_loss: 6.1014\nEpoch 5: early stopping\n","output_type":"stream"},{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7a58063ab5b0>"},"metadata":{}}]},{"cell_type":"code","source":"loss,accuracy=model.evaluate(X_test,Y_test)","metadata":{"execution":{"iopub.status.busy":"2024-09-17T04:20:15.428479Z","iopub.execute_input":"2024-09-17T04:20:15.428936Z","iopub.status.idle":"2024-09-17T04:20:15.526733Z","shell.execute_reply.started":"2024-09-17T04:20:15.428892Z","shell.execute_reply":"2024-09-17T04:20:15.525534Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stdout","text":"\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5268 - loss: 2.6420 \n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}