{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1183165,"sourceType":"datasetVersion","datasetId":672377}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport cv2\nfrom PIL import Image\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_path=\"/kaggle/input/brain-tumor-classification-mri/Training\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ext_data=[]\nfor images in os.listdir(data_path):\n    image=os.path.join(data_path,images)\n    ext_data.append(image)\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"var1=\"/kaggle/input/brain-tumor-classification-mri/Training/glioma_tumor\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"var1_data=[]\nfor images in os.listdir(var1):\n    image=os.path.join(var1,images)\n    image=Image.open(image)\n    var1_data.append(image)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# var1_data.isnull()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"var1_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for id,image in enumerate(var1_data):\n#     image1=image.show(image)\n# #     print(new_image)","metadata":{"_kg_hide-output":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cv2.imshow(var1_data)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cv2.imshow(\"Image\",var1_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# var1_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ext_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# x=cv2.imread(\"/kaggle/input/brain-tumor-classification-mri/Training/glioma_tumor\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cv2.imshow(\"Imgae\",x)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\nimport os\n\n# Directory containing the images\ndataset_dir = \"/kaggle/input/brain-tumor-classification-mri/Training/glioma_tumor\"\n\n# List to store image data\nimages = []\n\n# Iterate over files in the directory\nfor filename in os.listdir(dataset_dir):\n    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):  # Filter images\n        # Read the image\n        image_path = os.path.join(dataset_dir, filename)\n        image = cv2.imread(image_path)\n        if image is not None:\n            images.append(image)\n#         images.append(image)\n        else:\n            print(\"unable to load\")\n# images.show()\n\n# # # Display all images\n# for idx, image in enumerate(images):\n#     image.show()\n#     input(\"Press Enter to display the next image or Ctrl+C to exit...\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cv2.imshow(\"Image\",images)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import cv2\n# import os\n# import random\n\n# # Directory containing the images\n# dataset_dir = \"/kaggle/input/brain-tumor-classification-mri/Training/glioma_tumor\"\n# # List all image files in the directory\n# image_files = [os.path.join(dataset_dir, file) for file in os.listdir(dataset_dir) if file.endswith(('.png', '.jpg', '.jpeg'))]\n\n# # Number of images to display\n# num_images_to_display = 10\n\n# # Randomly select images to display\n# images_to_display = random.sample(image_files, min(num_images_to_display, len(image_files)))\n\n# # Display each image\n# for image_file in images_to_display:\n#     # Read the image\n#     image = cv2.imread(image_file)\n#     if image is not None:\n#         # Display the image\n#         cv2.imshow(\"Image\", image)\n#         cv2.waitKey(0)\n#         cv2.destroyAllWindows()\n#     else:\n#         print(f\"Unable to read image: {image_file}\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport os\nimport random\nimport matplotlib.pyplot as plt\n\n# Directory containing the images\ndataset_dir = \"/kaggle/input/brain-tumor-classification-mri/Training/glioma_tumor\"\n\n# List all image files in the directory\nimage_files = [os.path.join(dataset_dir, file) for file in os.listdir(dataset_dir) if file.endswith(('.png', '.jpg', '.jpeg'))]\n\n# Number of images to display\nnum_images_to_display = 10\n\n# Randomly select images to display\nimages_to_display = random.sample(image_files, min(num_images_to_display, len(image_files)))\n\n# Display each image\nfor image_file in images_to_display:\n    # Read the image\n    image = cv2.imread(image_file)\n    if image is not None:\n        # Convert BGR to RGB (matplotlib uses RGB)\n#         image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        # Display the image\n        plt.imshow(image)\n#         plt.axis('off')  # Hide axis\n        plt.show()\n    else:\n        print(f\"Unable to read image: {image_file}\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\n\n# Path to the PNG file\nfile_path = var1_data  # Replace this with the path to your PNG file\n\n# Read the PNG file\ntry:\n    image = Image.open(file_path)\n    # Optionally, you can perform further processing or display the image here\n    image.show()  # Opens the image using the default image viewer\nexcept IOError:\n    print(\"Unable to open or read the PNG file\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-11T06:59:39.342443Z","iopub.execute_input":"2024-05-11T06:59:39.342997Z","iopub.status.idle":"2024-05-11T06:59:39.885151Z","shell.execute_reply.started":"2024-05-11T06:59:39.342949Z","shell.execute_reply":"2024-05-11T06:59:39.882869Z"},"trusted":true},"execution_count":89,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/PIL/Image.py:3240\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3239\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3240\u001b[0m     \u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseek\u001b[49m(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m   3241\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, io\u001b[38;5;241m.\u001b[39mUnsupportedOperation):\n","\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'seek'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[89], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Read the PNG file\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 8\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# Optionally, you can perform further processing or display the image here\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     image\u001b[38;5;241m.\u001b[39mshow()  \u001b[38;5;66;03m# Opens the image using the default image viewer\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/PIL/Image.py:3242\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3240\u001b[0m     fp\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m   3241\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, io\u001b[38;5;241m.\u001b[39mUnsupportedOperation):\n\u001b[0;32m-> 3242\u001b[0m     fp \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO(\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m())\n\u001b[1;32m   3243\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   3245\u001b[0m prefix \u001b[38;5;241m=\u001b[39m fp\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m16\u001b[39m)\n","\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'read'"],"ename":"AttributeError","evalue":"'list' object has no attribute 'read'","output_type":"error"}]},{"cell_type":"code","source":"xdg-open /tmp/tmppvthta44.PNG","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport numpy as np\n\n# Define the desired dimensions for resizing\ndesired_width = 100\ndesired_height = 100\n\n# List to store resized image arrays\nimage_arrays = []\n\n# Loop through all image file paths\nfor image_path in data:\n    # Read the image using cv2\n    image = cv2.imread(image_path)\n    \n    # Resize the image to the desired dimensions\n    resized_image = cv2.resize(image, (desired_width, desired_height))\n    \n    # Append the resized image array to the list\n    image_arrays.append(resized_image)\n\n# Convert the list of image arrays into a NumPy array\nimage_array = np.array(image_arrays)\n\n# Now, 'image_array' contains the resized arrays of all images with consistent dimensions\n","metadata":{"execution":{"iopub.status.busy":"2024-05-11T06:59:45.730574Z","iopub.execute_input":"2024-05-11T06:59:45.732640Z","iopub.status.idle":"2024-05-11T06:59:45.809144Z","shell.execute_reply.started":"2024-05-11T06:59:45.732569Z","shell.execute_reply":"2024-05-11T06:59:45.806950Z"},"trusted":true},"execution_count":90,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)","Cell \u001b[0;32mIn[90], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(image_path)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Resize the image to the desired dimensions\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m resized_image \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdesired_width\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesired_height\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Append the resized image array to the list\u001b[39;00m\n\u001b[1;32m     20\u001b[0m image_arrays\u001b[38;5;241m.\u001b[39mappend(resized_image)\n","\u001b[0;31merror\u001b[0m: OpenCV(4.9.0) /io/opencv/modules/imgproc/src/resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n"],"ename":"error","evalue":"OpenCV(4.9.0) /io/opencv/modules/imgproc/src/resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n","output_type":"error"}]},{"cell_type":"code","source":"xdg-open --debug /tmp/tmppvthta44.PNG\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport os\nimport random\nimport matplotlib.pyplot as plt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_pathz=\"/kaggle/input/brain-tumor-classification-mri/Training/glioma_tumor\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def extract_data(data_pathz):\nnew_file_data=[]\ndata_file_img=[os.path.join(data_pathz,image) for image in os.listdir(data_pathz)]\n# for image in os.listdir(data_pathz):\n#     new_file = os.path.join(data_pathz,image)\nnew_file_random=random.sample(data_file_img, min(10,len(new_file)))\nfor random_new_img in new_file_random:\n#         if random_new_img is not None:\n    new_file1=cv2.imread(random_new_img)\n    if new_file1 is not None:\n        new_file_data.append(new_file1)\n#         plt.imshow(new_file1)\n#         plt.show()\n    else:\n        print(\"not found\")\n#             np.array(new_file_data)\n#     if new_file_data is not None:\n#         plt.imshow(new_file_data[0])\n#         plt.show()\n#     return new_file_data","metadata":{"execution":{"iopub.status.busy":"2024-05-11T06:59:49.487987Z","iopub.execute_input":"2024-05-11T06:59:49.488594Z","iopub.status.idle":"2024-05-11T06:59:49.564675Z","shell.execute_reply.started":"2024-05-11T06:59:49.488552Z","shell.execute_reply":"2024-05-11T06:59:49.563484Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Assuming new_file_data is your list of images\n# new_file_data = [...]\n\nnum_images = len(new_file_data)\n\n# Calculate number of rows and columns for subplots\nnum_cols = 3\nnum_rows = (num_images + num_cols - 1) // num_cols\n\n# Create subplots\nfig, axes = plt.subplots(num_rows, num_cols, figsize=(12, 8))\n\n# Plot each image\nfor i, ax in enumerate(axes.flat):\n    if i < num_images:\n        row = i // num_cols\n        col = i % num_cols\n        ax.imshow(new_file_data[i])\n        ax.set_title(f\"Image {i+1}\")\n        ax.axis('off')  # Hide axis\n    else:\n        ax.axis('off')  # Hide empty subplot\n\n# Adjust layout to prevent overlap\nplt.tight_layout()\n\n# Show plot\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.subplot(3,3,9)\nplt.plot(new_file_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_file_data\n# plt.imshow(new_file_data)\n# plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def extract_data(data_pathz):\nnew_file_data=[]\ndata_file_img=[os.path.join(data_pathz,image) for image in os.listdir(data_pathz)]\n# for image in os.listdir(data_pathz):\n#     new_file = os.path.join(data_pathz,image)\nnew_file_random=random.sample(data_file_img, min(10,len(new_file)))\nfor random_new_img in new_file_random:\n#         if random_new_img is not None:\n    new_file1=cv2.imread(random_new_img)\n    if new_file1 is not None:\n#         new_file_data.append(new_file1)\n        plt.imshow(new_file1)\n        plt.show()\n    else:\n        print(\"not found\")\n#             np.array(new_file_data)\n#     if new_file_data is not None:\n#         plt.imshow(new_file_data[0])\n#         plt.show()\n#     return new_file_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport os\nimport random\nimport matplotlib.pyplot as plt\n\n# Directory containing the images\ndataset_dir = \"/kaggle/input/brain-tumor-classification-mri/Training/glioma_tumor\"\n\n# List all image files in the directory\nimage_files = [os.path.join(dataset_dir, file) for file in os.listdir(dataset_dir) if file.endswith(('.png', '.jpg', '.jpeg'))]\n\n# Number of images to display\nnum_images_to_display = 10\n\n# Randomly select images to display\nimages_to_display = random.sample(image_files, min(num_images_to_display, len(image_files)))\n\n# Display each image\nfor image_file in images_to_display:\n    # Read the image\n    image = cv2.imread(image_file)\n    if image is not None:\n        # Convert BGR to RGB (matplotlib uses RGB)\n#         image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        # Display the image\n        plt.imshow(image)\n#         plt.axis('off')  # Hide axis\n        plt.show()\n    else:\n        print(f\"Unable to read image: {image_file}\")\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dir_train_path=\"/kaggle/input/brain-tumor-classification-mri/Training\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# new_img10=[]\n# for images in os.listdir(dir_train_path):\n#     ima=os.path.join(dir_train_path,images)\n#     if ima is not None:\n#         ima=cv2.imread(ima)\n#         new_img10.append(ima)\n#     for image in images:\n#         new_img1=os.path.join(ima,image)\n#         if new_img1 is not None:\n#             new_img2=cv2.imread(new_img1)\n#             new_img10.append(new_img2)\n       ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# new_img","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data=\"/kaggle/input/brain-tumor-classification-mri/Training/meningioma_tumor\"\ndata_no_tumor=\"/kaggle/input/brain-tumor-classification-mri/Training/no_tumor\"\ndata_pituitary_tumor=\"/kaggle/input/brain-tumor-classification-mri/Training/pituitary_tumor\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import random\n# random_image=random.sample(data,(10,len(data)))\ndata","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# data=pd.DataFrame(x,columns=[\"Glioma_tumor\"])\nglioma_tumor=extract_data(data_pathz)\nmeningioma_tumor=extract_data(data)\nno_tumor=extract_data(data_no_tumor)\npituitary_tumor=extract_data(data_pituitary_tumor)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(meningioma_tumor)\nprint(len(glioma_tumor))\nprint(len(no_tumor))\nprint(len(pituitary_tumor))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=pd.DataFrame(meningioma_tumor)\ndf.columns = [f'Pixel_{i}' for i in range(df.shape[1])]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import dopamine\nfrom dopamine.agents.dqn import dqn_agent\nfrom dopamine.atari import run_experiment\nfrom dopamine.colab import utils as colab_utils\nfrom absl import flags\n\n# Define flags for Dopamine\nBASE_PATH = '/tmp/colab_dope_run'\nLOG_PATH = os.path.join(BASE_PATH, 'basic_agent')\n\n# Set up flags to configure Dopamine\nLOG_PATH = os.path.join('/tmp/colab_dope_run', 'basic_agent')\n# Number of training steps\nflags.DEFINE_integer('num_iterations', 200, 'Number of training iterations.')\n# Path to the level script\nflags.DEFINE_string('game', 'CartPole-v0', 'Name of the Atari game to run.')\n\n# Flags to pass to the agent\nflags.DEFINE_boolean('verbose_logging', False, 'Whether to log progress verbose.')\nflags.DEFINE_boolean('notify_training_progress', True, 'Whether to log training progress.')\nflags.DEFINE_string('agent_name', 'dqn', 'Name of the agent to run.')\n\nFLAGS = flags.FLAGS\n\n\ndef create_dqn_agent(sess, environment):\n    \"\"\"Creates a DQN agent.\"\"\"\n    return dqn_agent.DQNAgent(sess, num_actions=environment.action_space.n)\n\n\ndef main():\n    # Set up logging\n    colab_utils.mount_google_drive()\n    experiment_logger = colab_utils.create_default_logger(LOG_PATH)\n\n    # Create an environment\n    environment = colab_utils.create_environment(FLAGS.game)\n\n    # Create a TensorFlow session\n    sess = colab_utils.create_session()\n\n    # Create the DQN agent\n    agent = create_dqn_agent(sess, environment)\n\n    # Initialize the agent\n    agent.initialize()\n\n    # Train the agent\n    run_experiment.run_experiment(\n        agent=agent,\n        environment=environment,\n        num_iterations=FLAGS.num_iterations,\n        training_steps=FLAGS.training_steps,\n        verbose_logging=FLAGS.verbose_logging,\n        notify_training_progress=FLAGS.notify_training_progress,\n        log_path=LOG_PATH\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install stable_baselines","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gym\nfrom stable_baselines3 import PPO\nfrom stable_baselines3.common.evaluation import evaluate_policy\n\n# Create the CartPole environment\nenv = gym.make('CartPole-v1')\n\n# Create and train the PPO agent\nmodel = PPO('MlpPolicy', env, verbose=1)\nmodel.learn(total_timesteps=10000)\n\n# Save the trained model\nmodel.save(\"ppo_cartpole\")\n\n# Load the trained model\nloaded_model = PPO.load(\"ppo_cartpole\")\n\n# Evaluate the trained model\nmean_reward, _ = evaluate_policy(loaded_model, env, n_eval_episodes=10)\nprint(\"Mean reward:\", mean_reward)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gym\nfrom stable_baselines3 import DQN\nfrom stable_baselines3.common.evaluation import evaluate_policy\n\n# Create the CartPole environment\nenv = gym.make('CartPole-v1')\n\n# Define and train the DQN agent\nmodel = DQN(\"MlpPolicy\", env, verbose=1)\nmodel.learn(total_timesteps=10000)\n\n# Save the trained model\nmodel.save(\"dqn_cartpole\")\n\n# Evaluate the trained model\nmean_reward, _ = model.evaluate(env, n_eval_episodes=10)\nprint(\"Mean reward:\", mean_reward)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gym\nimport tensorflow as tf\nfrom stable_baselines3 import DQN\nfrom stable_baselines3.dqn import MlpPolicy\n\n# Define the CartPole environment\nenv = gym.make('CartPole-v1')\n\n# Define the neural network architecture for the policy using Keras\ndef create_model(input_dim, output_dim):\n    model = tf.keras.Sequential([\n        tf.keras.layers.Dense(64, activation='relu', input_shape=(input_dim,)),\n        tf.keras.layers.Dense(64, activation='relu'),\n        tf.keras.layers.Dense(output_dim, activation='linear')\n    ])\n    return model\n\n# Create the neural network model\npolicy_kwargs = dict(\n    net_arch=create_model,  # Specify the neural network architecture function\n    features_extractor_kwargs={\"features_dim\": env.observation_space.shape[0]}\n)\n\n# Create and train the DQN agent with the specified policy\nmodel = DQN(MlpPolicy, env, policy_kwargs=policy_kwargs, verbose=1)\nmodel.learn(total_timesteps=10000)\n\n# Save the trained model\nmodel.save(\"dqn_cartpole\")\n\n# Evaluate the trained model\nmean_reward, _ = model.evaluate(env, n_eval_episodes=10)\nprint(\"Mean reward:\", mean_reward)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}