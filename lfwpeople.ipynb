{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":796646,"sourceType":"datasetVersion","datasetId":19136}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport os\nimport cv2\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tarfile\n\ntgz_file = '/kaggle/input/lfwpeople/lfw-funneled.tgz'\nextract_path = '/kaggle/working/'\n\nwith tarfile.open(tgz_file, 'r:gz') as tar:\n    tar.extractall(path=extract_path)\n    print(f\"Extracted files to {extract_path}\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ai_data=\"/kaggle/input/ai-generated-images\"\nnew_data_ai=[]\nfor a in os.listdir(ai_data):\n    data=os.path.join(ai_data,a)\n    new_data_ai.append(data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_data_ai","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# original image data","metadata":{}},{"cell_type":"code","source":"new_df=[]\nfor cur,diri,filename in os.walk('/kaggle/working/lfw_funneled'):\n    for file in filename:\n        if not file.endswith('.txt'):\n            data=os.path.join(cur,file)\n            new_df.append(data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"read_image","metadata":{}},{"cell_type":"code","source":"new_fd=[]\nfor i in new_df:\n    cv=cv2.imread(i)\n    if cv is not None:\n        data4=cv2.resize(cv,(250,250))\n        new_fd.append(data4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(new_fd)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_df_orginal=new_fd[0:115]\nnew_df_orginal=np.array(new_df_orginal)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# original data label for 115 image","metadata":{}},{"cell_type":"code","source":"lt=[]\nfor _ in range(115):\n    rt=0\n    lt.append(rt)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(lt)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ai image data","metadata":{}},{"cell_type":"code","source":"new_df_ai=[]\nfor cur,diri,filename in os.walk('/kaggle/input/d/syedbasit1/ai-generated-images/ai generated images'):\n    for file in filename:\n        data_ai=os.path.join(cur,file)\n        cv=cv2.imread(data_ai)\n        if cv is not None:\n            cv1=cv2.resize(cv,(250,250))\n            new_df_ai.append(cv1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_df_ai_image=np.array(new_df_ai)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(new_df_ai)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i,value in enumerate(new_df_ai):\n    plt.imshow(new_df_ai[11])\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(new_df_ai)\n# new_data_ai.shape()\n# nda=np.array(new_df_ai)\n# nda.dtypes\n# nda=pd.DataFrame(nda)\nnda.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ai image label","metadata":{}},{"cell_type":"code","source":"ad=[]\nfor _ in range(115):\n    a=1\n    ad.append(a)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(ad)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# # concat","metadata":{}},{"cell_type":"code","source":"new_df_ai_image.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\n\nnew_df_ai_image = new_df_ai_image.astype(np.uint8)\nnew_df_orginal = new_df_orginal.astype(np.uint8)\n\n# Perform the addition\nconcat_image = new_df_ai_image + new_df_orginal\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"concat_image=new_df_ai_image+new_df_orginal","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# # train on pre trained model","metadata":{}},{"cell_type":"code","source":"nda","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# face detection on image dataset","metadata":{}},{"cell_type":"code","source":"import cv2\nimport matplotlib.pyplot as plt\n\n\nface_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n\ndef detect_faces_opencv(image):\n    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n    return faces\n\ndef process_images(image_paths):\n    new_df_model=[]\n    for image_path in image_paths:\n       \n        image = cv2.imread(image_path)\n        if image is None:\n            print(f\"Warning: Unable to load image at path '{image_path}'\")\n            continue\n\n        faces = detect_faces_opencv(image)\n        \n        for (x, y, w, h) in faces:\n            cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n        \n\n        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n        new_df_model.append(image_rgb)       \n    return new_df_model\n\n\nhd_df=process_images(new_df)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(hd_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(hd_df[10])\nplt.axis('off')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# # text data","metadata":{}},{"cell_type":"code","source":"tx1=\"/kaggle/input/lfwpeople/pairs.txt\"\n# with open(tx1,'r') as tx:\n#     content=tx.read()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import csv\ndt=[]\n# Open and read the file\nwith open(tx1, 'r') as file:\n    reader = csv.reader(file, delimiter='\\t')\n    for row in reader:\n#         print(row)  # Each row is a list of columns\n        dt.append(row)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dt[0:3]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dr=pd.DataFrame(dt)\ndr","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dy=[]\nwith open('/kaggle/input/lfwpeople/pairs.txt', 'r') as file:\n    data = file.readlines()\n\n\nfor line in data:\n    t=line.strip()\n    dy.append(t)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"c=csv.reader(dy,delimiter='\\t')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"s=[]\nfor r in c:\n    s.append(r)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a=pd.DataFrame(s,columns=[\"Name1\",\"col12\",\"Name3\",\"col14\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"concaty_y=a[[\"Name1\"]]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"concaty_y[:34]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(concaty)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"concaty_y.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# # train model","metadata":{}},{"cell_type":"code","source":"hd_df1=np.array(hd_df)\nhd_df1.dtype","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train,X_test=train_test_split(hd_df1[0:6000,:])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_encoder=LabelEncoder()\nlabel=label_encoder.fit_transform(concaty_y)\nlabel.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_train,Y_test=train_test_split(label[0:6000])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\n\nnum_classes = len(Y_train)\nprint(f\"Number of classes: {num_classes}\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Input\nfrom tensorflow.keras.optimizers import Adam\n\n# Define the model\nmodel = Sequential([\n    Input(shape=(250, 250, 3)),  \n    Conv2D(32, (3, 3), activation='relu', padding='same'),\n    Conv2D(32, (3, 3), activation='relu', padding='same'),\n    MaxPooling2D(2, 2),\n    Flatten(),\n    Dense(128, activation='relu'),\n    Dense(num_classes, activation='softmax')\n])\n\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\nmodel.summary()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(X_train, Y_train, epochs=1,validation_split=0.2)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\nprint(f'Test accuracy: {test_acc}')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred=model.predict(X_test)\ndecoded_labels = label_encoder.inverse_transform(y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# # test_model","metadata":{}},{"cell_type":"code","source":"inputs=(\"image.jpg\")\nimg=cv2.imread(inputs)\nimg2=cv2.resize(img,(250,250))\nmod_p=model.predict(img2)\ndecoded_labels = label_encoder.inverse_transform(y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# # Face Detection ","metadata":{}},{"cell_type":"code","source":"import cv2\ndef face_detection(image_path):\n    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n\n\n    \n    image = cv2.imread(image_path)\n    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n\n    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n\n    for (x, y, w, h) in faces:\n    cv2.rectangle(image, (x, y), (x+w, y+h), (255, 0, 0), 2)\n\n    return image\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"face_detection(\"image.jpg\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}